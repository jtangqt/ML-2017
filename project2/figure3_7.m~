%%Plots Figure 3.7

close all; clc; clear all; 
N = 20; 
x = 2*rand(1,N)-1;
a0 = -0.3;
a1 = 0.5;  
w = [a0 a1];
n_sigma = 0.2;
noise = n_sigma*randn(1,N); %generates noise with standard deviation of 0.2
beta = 1/(n_sigma)^2; %precision parameter
alpha = 2; %hyperparameter for prior
phi = zeros(N, 2); 
m0 = zeros(length(w), 1);
S0 = alpha^(-1)*eye(length(w));
matrix = zeros(2*N, 6); 
lse = zeros(2*N, 1);
prior = mvnrnd(m0, S0, 6)';

phi = [ones(N, 1) x'];
    
y = linear_reg(x, a0, a1); %creates the linear regression line
y = y + noise; %adds noise to create randomness 

%likelihood and posterior
for i = 1:N
    SN = pinv(pinv(S0) + beta*phi(1:i, :)'*phi(1:i, :));
    mN = SN*(pinv(S0)*m0 + beta*phi(1:i, :)'*y(1:i)');
    matrix(2*i-1:2*i,:) = mvnrnd(mN, SN, 6)'; 
    mN_lse(2*i-1:2*i) = pinv(alpha/beta*eye(length(w))+phi(1:i, :)'*phi(1:i, :))*phi(1:i, :)'*y(1:i)';
end
   
    w0 = -1:0.01:1;
    w1 = -1:0.01:1;
    [W0,W1] = meshgrid(a0,a1);

    figure
    colormap('jet') 
    %likelihood
    subplot(1, 3, 1); 
    phi0_l = 1; 
    phi1_l = x(n); 
    ml = W0*phi0_l + W1*phi1_l;
    sl = 1/beta; 
    prob_l = 1/(2*pi*sl)^(1/2)*exp(-1/(2*sl)*(t(n)-ml).^2);
    imagesc(a0, a1, prob_l)

    %posterior/prior
    subplot(1, 3, 2); 

    %dataspace 
    subplot(1, 3, 3); 
    
figure; 
scatter(x,y); 